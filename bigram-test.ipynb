{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "block_size = 64\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = .2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading, Encoding, and Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./merged_data.csv')\n",
    "full_str = ''\n",
    "for i, row in df.iterrows():\n",
    "    content = row.content\n",
    "    full_str += ' ' + content\n",
    "\n",
    "chars = sorted(list(set(full_str)))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {ch: i for i, ch in enumerate(chars)}\n",
    "gnippam = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda st: [mapping[ch] for ch in st]\n",
    "decode = lambda ls: ''.join([gnippam[i] for i in ls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(data=encode(full_str), dtype=torch.long)\n",
    "n = int(.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    '''generate a small batch of data of inputs x and targets y'''\n",
    "    \n",
    "    data = train_data if split == 'train' else val_data\n",
    "\n",
    "    ix = torch.randint(\n",
    "        low=0,\n",
    "        high=len(data) - block_size,\n",
    "        size=(batch_size,)\n",
    "    )\n",
    "    x = torch.stack(tensors=[data[i:i+block_size] for i in ix]).to(device)\n",
    "    y = torch.stack(tensors=[data[i+1:i+1+block_size] for i in ix]).to(device)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = get_batch(split='test')[0]\n",
    "test_list = []\n",
    "for row in test_tensor:\n",
    "    for element in row:\n",
    "        test_list.append(element.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" each was about 4%. We are expecting low-single-digit, slightly egory when we get more funding.\\nOperator: Thank you. Our next quve for next year is $750 million of COVID testing related revenu comparisons will be chunky this year. Turning to regulatory filt you're seeing tremendous leasing demand, restaurant demand, etarting to flatten but just to catch up on all the other inflatiohis year, demonstrate the strength and diversity of our portfoli the transportation for the long haul. I'm not telling you that VAC. And can you give a sense of sell-through you saw in the fir Carestio, maybe I can give you a little information on the mark envelope math, it sounds like it could be a little bit negativeis firmly on track. Moving now on to Slide 8. The strength of ouDay, we shared with you our plans and commitment for C-Band and think, probably the best way to think about that as we're workinadvantage of rate cases if we need to.  But we've done a really and active oriented franchises. Vans ranked #1 among the largestill land between those figures on a full year basis. Most importty-related. So I will say this to you. I believe that’s the nexterage cash value of that total loss is up pretty significantly. nization two or three years ago. We’re going to open 60 more of aendel St. Juste: Hey. Good evening, out there.\\nDavid Simon: We' were in excess of 90% and compliance rates exceeded our initialur first question comes from line of Robbie Marcus from JPMorgant of the bookends around the expense growth trajectory that thategulatory for a while now. I guess the one thing that might be dband. But early into it, I'm really pleased what the technology I think we'd be down probably in the mid- to low 50s. But it's jld be based on your guidance, you've had a growth target in the exity of threats continue to increase due to factors including gtrock.com or via a link on the application you are using to viewYes, Julien. I mean, we look at a couple of things, right? We ha. What likely you've read in the press release and our supplemen\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Self-Attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    '''A single head of self attention.'''\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()                                                                  # Access to nn functions/classes\n",
    "        self.key = nn.Linear(in_features=n_embd, out_features=head_size, bias=False)        # Determines attention to other elements\n",
    "        self.query = nn.Linear(in_features=n_embd, out_features=head_size, bias=False)      # Determines similarity/relevance of other elements to input element\n",
    "        self.value = nn.Linear(in_features=n_embd, out_features=head_size, bias=False)      # Actual info associated with the element\n",
    "        self.register_buffer(                                                               # Attention only applied to past elements\n",
    "            name='tril',\n",
    "            tensor=torch.tril(input=torch.ones(block_size, block_size))     # Lower triangular tensor of ones\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=dropout)                                                # Randomly drop `dropout` fraction of the neurons\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape                                                   # B=batch size, T=sequence length, C=feature dim    \n",
    "        k = self.key(x)                                                     # applies key layer to x\n",
    "        q = self.query(x)                                                   # applies query layer to x\n",
    "        v = self.value(x)                                                   # applies value layer to x\n",
    "\n",
    "        wei = q @ k.transpose(-2, -1) * C ** -0.5                           # computes pairwise similarity of keys and queries -> weights\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))        # applies masking\n",
    "        wei = F.softmax(wei, dim=-1)                                        # normalize the weights so they form a probability distribution\n",
    "        wei = self.dropout(wei)                                             # applies dropout layer\n",
    "        out = wei @ v                                                       # aggregate values based on weights\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = Head(head_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_weights = head.key.weight\n",
    "query_weights = head.query.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) torch.Size([2, 3, 1]) torch.Size([2, 3, 128])\n"
     ]
    }
   ],
   "source": [
    "unsqueeze_test_tensor = torch.tensor([[1,2,3],[4,5,6]])         # shape (2,3)\n",
    "unsqueezed_tensor = unsqueeze_test_tensor.unsqueeze(dim=-1)     # inserts singleton dimension at idx -1\n",
    "expanded_tensor = unsqueezed_tensor.expand(-1,-1,n_embd)        # replicates the tensor along specified dims\n",
    "print(unsqueeze_test_tensor.shape, unsqueezed_tensor.shape, expanded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64])\n",
      "torch.Size([32, 64, 128])\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch('train')\n",
    "print(x.shape)\n",
    "x = x.unsqueeze(-1).expand(-1,-1,n_embd)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "B,T,C = x.shape\n",
    "k = head.key(x)\n",
    "q = head.query(x)\n",
    "v = head.value(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 16]) torch.Size([32, 16, 64])\n"
     ]
    }
   ],
   "source": [
    "k_transpose = k.transpose(-2,-1)\n",
    "print(k.shape, k_transpose.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "wei = q @ k.transpose(-2, -1) * C ** -0.5                           # computes pairwise similarity of keys and queries -> weights\n",
    "wei = wei.masked_fill(head.tril[:T, :T] == 0, float('-inf'))        # applies masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "wei = F.softmax(wei, dim=-1)                                        # normalize the weights so they form a probability distribution\n",
    "wei = head.dropout(wei)                                             # applies dropout layer\n",
    "out = wei @ v                                                       # aggregate values based on weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_arr = out.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_out_arr(idx):\n",
    "    plt.imshow(out_arr[idx])  # Assuming batch_size=1\n",
    "    plt.colorbar(label=\"Attention Weight\")\n",
    "    plt.title(\"Attention Weights Heatmap\")\n",
    "    plt.xlabel(\"Input Sequence Position\")\n",
    "    plt.ylabel(\"Input Sequence Position\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-topic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
